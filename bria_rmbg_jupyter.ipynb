{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/bria-rmbg-jupyter/blob/main/bria_rmbg_jupyter.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio\n",
        "!wget https://github.com/camenduru/BRIA-RMBG-1.4-hf/raw/main/briarmbg.py -O briarmbg.py\n",
        "!wget https://github.com/camenduru/BRIA-RMBG-1.4-hf/raw/main/input.jpg -O input.jpg\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms.functional import normalize\n",
        "from huggingface_hub import hf_hub_download\n",
        "import gradio as gr\n",
        "from briarmbg import BriaRMBG\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from typing import Tuple\n",
        "\n",
        "net=BriaRMBG()\n",
        "model_path = hf_hub_download(\"briaai/RMBG-1.4\", 'model.pth')\n",
        "if torch.cuda.is_available():\n",
        "    net.load_state_dict(torch.load(model_path))\n",
        "    net=net.cuda()\n",
        "else:\n",
        "    net.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n",
        "net.eval() \n",
        "    \n",
        "def resize_image(image):\n",
        "    image = image.convert('RGB')\n",
        "    model_input_size = (1024, 1024)\n",
        "    image = image.resize(model_input_size, Image.BILINEAR)\n",
        "    return image\n",
        "\n",
        "def process(image):\n",
        "    orig_image = Image.fromarray(image)\n",
        "    w,h = orig_im_size = orig_image.size\n",
        "    image = resize_image(orig_image)\n",
        "    im_np = np.array(image)\n",
        "    im_tensor = torch.tensor(im_np, dtype=torch.float32).permute(2,0,1)\n",
        "    im_tensor = torch.unsqueeze(im_tensor,0)\n",
        "    im_tensor = torch.divide(im_tensor,255.0)\n",
        "    im_tensor = normalize(im_tensor,[0.5,0.5,0.5],[1.0,1.0,1.0])\n",
        "    if torch.cuda.is_available():\n",
        "        im_tensor=im_tensor.cuda()\n",
        "\n",
        "    result=net(im_tensor)\n",
        "    result = torch.squeeze(F.interpolate(result[0][0], size=(h,w), mode='bilinear') ,0)\n",
        "    ma = torch.max(result)\n",
        "    mi = torch.min(result)\n",
        "    result = (result-mi)/(ma-mi)    \n",
        "    im_array = (result*255).cpu().data.numpy().astype(np.uint8)\n",
        "    pil_im = Image.fromarray(np.squeeze(im_array))\n",
        "    new_im = Image.new(\"RGBA\", pil_im.size, (0,0,0,0))\n",
        "    new_im.paste(orig_image, mask=pil_im)\n",
        "    return new_im\n",
        "\n",
        "gr.Markdown(\"## BRIA RMBG 1.4\")\n",
        "gr.HTML('''\n",
        "  <p style=\"margin-bottom: 10px; font-size: 94%\">\n",
        "    This is a demo for BRIA RMBG 1.4 that using\n",
        "    <a href=\"https://huggingface.co/briaai/RMBG-1.4\" target=\"_blank\">BRIA RMBG-1.4 image matting model</a> as backbone. \n",
        "  </p>\n",
        "''')\n",
        "title = \"Background Removal\"\n",
        "description = r\"\"\"Background removal model developed by <a href='https://BRIA.AI' target='_blank'><b>BRIA.AI</b></a>, trained on a carefully selected dataset and is available as an open-source model for non-commercial use.<br> \n",
        "For test upload your image and wait. Read more at model card <a href='https://huggingface.co/briaai/RMBG-1.4' target='_blank'><b>briaai/RMBG-1.4</b></a>.<br>\n",
        "\"\"\"\n",
        "examples = [['./input.jpg'],]\n",
        "demo = gr.Interface(fn=process,inputs=\"image\", outputs=\"image\", examples=examples, title=title, description=description)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True, share=True, inline=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
